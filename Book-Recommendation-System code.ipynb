{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d12be412-b279-411e-be2e-806ec27c1ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mycom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mycom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mycom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mycom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.data import path as nltk_data_path\n",
    "from nltk.corpus import wordnet\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Korean NLP library\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# Visualization and miscellaneous\n",
    "import operator\n",
    "import statistics\n",
    "\n",
    "# Configuration for NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk_data_path.append('C:/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed20ec0-f0b1-4e1f-b4af-13a6faeb6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "students_books_df = pd.read_csv('data/book_rent.csv')\n",
    "books_df = pd.read_csv('data/book_list(2).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce7b140-83c8-4a1d-981a-685387e0ec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   student_id  20000 non-null  int64\n",
      " 1   book_id     20000 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 312.6 KB\n"
     ]
    }
   ],
   "source": [
    "students_books_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b72b40-7b8d-423a-a23f-02a36f64676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9862 entries, 0 to 9861\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   서지번호    9862 non-null   int64 \n",
      " 1   서명      9862 non-null   object\n",
      " 2   저자      9829 non-null   object\n",
      " 3   발행처     9859 non-null   object\n",
      " 4   출판년도    9859 non-null   object\n",
      " 5   ISBN    7894 non-null   object\n",
      " 6   청구기호    9862 non-null   int64 \n",
      " 7   언어      9862 non-null   object\n",
      " 8   서지유형    9862 non-null   object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 693.6+ KB\n"
     ]
    }
   ],
   "source": [
    "books_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb2cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['청구기호'] = books_df['청구기호'].astype(str)\n",
    "\n",
    "books_df['대분류'] = books_df['청구기호'].str[0]\n",
    "books_df['소분류'] = books_df['청구기호'].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b024a92-b5c0-4a8c-9ae9-f0ad342d353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['대분류'] = books_df['대분류'].astype(str)\n",
    "books_df['소분류'] = books_df['소분류'].astype(str)\n",
    "\n",
    "books_df = books_df.drop(labels='청구기호',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf652f3-8469-48ce-ad2e-c730ee9a97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # 정규 표현식 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f942746e-8b26-4be7-b649-bb3015233853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 이름 변경 및 데이터 병합\n",
    "books_df = books_df.rename(columns={'서지번호': 'book_id'})\n",
    "data = students_books_df.merge(books_df, how='inner', on='book_id')\n",
    "\n",
    "# 책 정보 텍스트 전처리 함수\n",
    "def preprocess_text_multilingual(text, language='en'):\n",
    "    if language == 'en':\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "        tokens = word_tokenize(text)\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(word) for word in tokens]\n",
    "        return ' '.join(tokens)\n",
    "    elif language == 'ko':\n",
    "        text = re.sub(r'[^\\uac00-\\ud7a3\\s]', '', text)\n",
    "        okt = Okt()\n",
    "        tokens = okt.morphs(text, stem=True)\n",
    "        stop_words = set(['은', '는', '이', '가', '를', '에', '의', '도', '으로', '그리고', '하지만', '또는'])\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported language. Use 'en' for English or 'ko' for Korean.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e26651-f266-4361-9504-ef07a3a8c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 컬럼 전처리\n",
    "books_df['저자'] = books_df['저자'].fillna('').astype(str).apply(lambda x: preprocess_text_multilingual(x, language='ko'))\n",
    "books_df['발행처'] = books_df['발행처'].fillna('').astype(str).apply(lambda x: preprocess_text_multilingual(x, language='ko'))\n",
    "books_df['출판년도'] = books_df['출판년도'].fillna('').astype(str).apply(lambda x: preprocess_text_multilingual(x, language='ko'))\n",
    "\n",
    "# 책 속성 결합\n",
    "books_df['book_features'] = (\n",
    "    books_df['서명'].fillna('') + ' ' +\n",
    "    books_df['저자'] + ' ' +\n",
    "    books_df['발행처'] + ' ' +\n",
    "    books_df['서지유형'].fillna('') + ' ' +\n",
    "    books_df['대분류'].fillna('') + ' ' +\n",
    "    books_df['소분류'].fillna('')\n",
    ")\n",
    "\n",
    "# 결합한 데이터에서 결측값 처리\n",
    "books_df['book_features'] = books_df['book_features'].fillna('')\n",
    "\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(books_df['book_features'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Doc2Vec 벡터 변환\n",
    "documents = [TaggedDocument(words=content.split(), tags=[str(i)]) for i, content in enumerate(books_df['book_features'])]\n",
    "doc2vec_model = Doc2Vec(documents, vector_size=200, window=5, min_count=2, epochs=40)\n",
    "content_vectors = np.array([doc2vec_model.dv[str(i)] for i in range(len(books_df['book_features']))])\n",
    "\n",
    "# TF-IDF와 Doc2Vec 기반 유사도 계산\n",
    "article_similarity_tfidf = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "article_similarity_doc2vec = cosine_similarity(content_vectors)\n",
    "article_similarity_total = 0.5 * article_similarity_tfidf + 0.5 * article_similarity_doc2vec\n",
    "\n",
    "# 학생-책 행렬 생성 (유저-아이템 행렬)\n",
    "students_books_df['interaction'] = 1\n",
    "user_article_matrix = students_books_df.pivot_table(index='student_id', columns='book_id', values='interaction', fill_value=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28193b6a-1b7e-4221-8bff-d4eb127dc341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_article_matrix.shape: (500, 9862)\n",
      "article_similarity_total.shape: (9862, 9862)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: book_id 매핑\n",
    "book_id_mapping = {book_id: idx for idx, book_id in enumerate(students_books_df['book_id'].unique())}\n",
    "students_books_df['mapped_book_id'] = students_books_df['book_id'].map(book_id_mapping)\n",
    "\n",
    "# Step 2: article_similarity_total의 크기에 맞춰 book_id_mapping 확장\n",
    "expected_book_ids = range(article_similarity_total.shape[0])\n",
    "for book_id in expected_book_ids:\n",
    "    if book_id not in book_id_mapping:\n",
    "        book_id_mapping[book_id] = len(book_id_mapping)\n",
    "\n",
    "# Step 3: 확장된 매트릭스 초기화\n",
    "num_books_total = article_similarity_total.shape[0]\n",
    "expanded_matrix = np.zeros((user_article_matrix.shape[0], num_books_total))\n",
    "\n",
    "# Step 4: user_article_matrix 데이터를 확장된 매트릭스에 복사\n",
    "for book_id, idx in book_id_mapping.items():\n",
    "    # 유효한 book_id와 user_article_matrix의 열 범위를 체크\n",
    "    if idx < user_article_matrix.shape[1] and book_id < expanded_matrix.shape[1]:\n",
    "        expanded_matrix[:, book_id] = user_article_matrix[:, idx]\n",
    "\n",
    "# Step 5: user_article_matrix 업데이트 및 크기 검증\n",
    "user_article_matrix = expanded_matrix\n",
    "assert user_article_matrix.shape[1] == article_similarity_total.shape[0], \"행렬의 열 크기가 여전히 불일치합니다.\"\n",
    "\n",
    "# Debugging: 최종 크기 출력\n",
    "print(\"user_article_matrix.shape:\", user_article_matrix.shape)\n",
    "print(\"article_similarity_total.shape:\", article_similarity_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c07b68c0-2de0-4046-8d1a-d15b624623e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "누락된 book_id: {8656, 8657, 8658, 8659, 8660, 8661, 8662, 8663, 8664, 8665, 8666, 8667, 8668, 8669, 8670, 8671, 8672, 8673, 8674, 8675, 8676, 8677, 8678, 8679, 8680, 8681, 8682, 8683, 8684, 8685, 8686, 8687, 8688, 8689, 8690, 8691, 8692, 8693, 8694, 8695, 8696, 8697, 8698, 8699, 8700, 8701, 8702, 8703, 8704, 8705, 8706, 8707, 8708, 8709, 8710, 8711, 8712, 8713, 8714, 8715, 8716, 8717, 8718, 8719, 8720, 8721, 8722, 8723, 8724, 8725, 8726, 8727, 8728, 8729, 8730, 8731, 8732, 8733, 8734, 8735, 8736, 8737, 8738, 8739, 8740, 8741, 8742, 8743, 8744, 8745, 8746, 8747, 8748, 8749, 8750, 8751, 8752, 8753, 8754, 8755, 8756, 8757, 8758, 8759, 8760, 8761, 8762, 8763, 8764, 8765, 8766, 8767, 8768, 8769, 8770, 8771, 8772, 8773, 8774, 8775, 8776, 8777, 8778, 8779, 8780, 8781, 8782, 8783, 8784, 8785, 8786, 8787, 8788, 8789, 8790, 8791, 8792, 8793, 8794, 8795, 8796, 8797, 8798, 8799, 8800, 8801, 8802, 8803, 8804, 8805, 8806, 8807, 8808, 8809, 8810, 8811, 8812, 8813, 8814, 8815, 8816, 8817, 8818, 8819, 8820, 8821, 8822, 8823, 8824, 8825, 8826, 8827, 8828, 8829, 8830, 8831, 8832, 8833, 8834, 8835, 8836, 8837, 8838, 8839, 8840, 8841, 8842, 8843, 8844, 8845, 8846, 8847, 8848, 8849, 8850, 8851, 8852, 8853, 8854, 8855, 8856, 8857, 8858, 8859, 8860, 8861, 8862, 8863, 8864, 8865, 8866, 8867, 8868, 8869, 8870, 8871, 8872, 8873, 8874, 8875, 8876, 8877, 8878, 8879, 8880, 8881, 8882, 8883, 8884, 8885, 8886, 8887, 8888, 8889, 8890, 8891, 8892, 8893, 8894, 8895, 8896, 8897, 8898, 8899, 8900, 8901, 8902, 8903, 8904, 8905, 8906, 8907, 8908, 8909, 8910, 8911, 8912, 8913, 8914, 8915, 8916, 8917, 8918, 8919, 8920, 8921, 8922, 8923, 8924, 8925, 8926, 8927, 8928, 8929, 8930, 8931, 8932, 8933, 8934, 8935, 8936, 8937, 8938, 8939, 8940, 8941, 8942, 8943, 8944, 8945, 8946, 8947, 8948, 8949, 8950, 8951, 8952, 8953, 8954, 8955, 8956, 8957, 8958, 8959, 8960, 8961, 8962, 8963, 8964, 8965, 8966, 8967, 8968, 8969, 8970, 8971, 8972, 8973, 8974, 8975, 8976, 8977, 8978, 8979, 8980, 8981, 8982, 8983, 8984, 8985, 8986, 8987, 8988, 8989, 8990, 8991, 8992, 8993, 8994, 8995, 8996, 8997, 8998, 8999, 9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016, 9017, 9018, 9019, 9020, 9021, 9022, 9023, 9024, 9025, 9026, 9027, 9028, 9029, 9030, 9031, 9032, 9033, 9034, 9035, 9036, 9037, 9038, 9039, 9040, 9041, 9042, 9043, 9044, 9045, 9046, 9047, 9048, 9049, 9050, 9051, 9052, 9053, 9054, 9055, 9056, 9057, 9058, 9059, 9060, 9061, 9062, 9063, 9064, 9065, 9066, 9067, 9068, 9069, 9070, 9071, 9072, 9073, 9074, 9075, 9076, 9077, 9078, 9079, 9080, 9081, 9082, 9083, 9084, 9085, 9086, 9087, 9088, 9089, 9090, 9091, 9092, 9093, 9094, 9095, 9096, 9097, 9098, 9099, 9100, 9101, 9102, 9103, 9104, 9105, 9106, 9107, 9108, 9109, 9110, 9111, 9112, 9113, 9114, 9115, 9116, 9117, 9118, 9119, 9120, 9121, 9122, 9123, 9124, 9125, 9126, 9127, 9128, 9129, 9130, 9131, 9132, 9133, 9134, 9135, 9136, 9137, 9138, 9139, 9140, 9141, 9142, 9143, 9144, 9145, 9146, 9147, 9148, 9149, 9150, 9151, 9152, 9153, 9154, 9155, 9156, 9157, 9158, 9159, 9160, 9161, 9162, 9163, 9164, 9165, 9166, 9167, 9168, 9169, 9170, 9171, 9172, 9173, 9174, 9175, 9176, 9177, 9178, 9179, 9180, 9181, 9182, 9183, 9184, 9185, 9186, 9187, 9188, 9189, 9190, 9191, 9192, 9193, 9194, 9195, 9196, 9197, 9198, 9199, 9200, 9201, 9202, 9203, 9204, 9205, 9206, 9207, 9208, 9209, 9210, 9211, 9212, 9213, 9214, 9215, 9216, 9217, 9218, 9219, 9220, 9221, 9222, 9223, 9224, 9225, 9226, 9227, 9228, 9229, 9230, 9231, 9232, 9233, 9234, 9235, 9236, 9237, 9238, 9239, 9240, 9241, 9242, 9243, 9244, 9245, 9246, 9247, 9248, 9249, 9250, 9251, 9252, 9253, 9254, 9255, 9256, 9257, 9258, 9259, 9260, 9261, 9262, 9263, 9264, 9265, 9266, 9267, 9268, 9269, 9270, 9271, 9272, 9273, 9274, 9275, 9276, 9277, 9278, 9279, 9280, 9281, 9282, 9283, 9284, 9285, 9286, 9287, 9288, 9289, 9290, 9291, 9292, 9293, 9294, 9295, 9296, 9297, 9298, 9299, 9300, 9301, 9302, 9303, 9304, 9305, 9306, 9307, 9308, 9309, 9310, 9311, 9312, 9313, 9314, 9315, 9316, 9317, 9318, 9319, 9320, 9321, 9322, 9323, 9324, 9325, 9326, 9327, 9328, 9329, 9330, 9331, 9332, 9333, 9334, 9335, 9336, 9337, 9338, 9339, 9340, 9341, 9342, 9343, 9344, 9345, 9346, 9347, 9348, 9349, 9350, 9351, 9352, 9353, 9354, 9355, 9356, 9357, 9358, 9359, 9360, 9361, 9362, 9363, 9364, 9365, 9366, 9367, 9368, 9369, 9370, 9371, 9372, 9373, 9374, 9375, 9376, 9377, 9378, 9379, 9380, 9381, 9382, 9383, 9384, 9385, 9386, 9387, 9388, 9389, 9390, 9391, 9392, 9393, 9394, 9395, 9396, 9397, 9398, 9399, 9400, 9401, 9402, 9403, 9404, 9405, 9406, 9407, 9408, 9409, 9410, 9411, 9412, 9413, 9414, 9415, 9416, 9417, 9418, 9419, 9420, 9421, 9422, 9423, 9424, 9425, 9426, 9427, 9428, 9429, 9430, 9431, 9432, 9433, 9434, 9435, 9436, 9437, 9438, 9439, 9440, 9441, 9442, 9443, 9444, 9445, 9446, 9447, 9448, 9449, 9450, 9451, 9452, 9453, 9454, 9455, 9456, 9457, 9458, 9459, 9460, 9461, 9462, 9463, 9464, 9465, 9466, 9467, 9468, 9469, 9470, 9471, 9472, 9473, 9474, 9475, 9476, 9477, 9478, 9479, 9480, 9481, 9482, 9483, 9484, 9485, 9486, 9487, 9488, 9489, 9490, 9491, 9492, 9493, 9494, 9495, 9496, 9497, 9498, 9499, 9500, 9501, 9502, 9503, 9504, 9505, 9506, 9507, 9508, 9509, 9510, 9511, 9512, 9513, 9514, 9515, 9516, 9517, 9518, 9519, 9520, 9521, 9522, 9523, 9524, 9525, 9526, 9527, 9528, 9529, 9530, 9531, 9532, 9533, 9534, 9535, 9536, 9537, 9538, 9539, 9540, 9541, 9542, 9543, 9544, 9545, 9546, 9547, 9548, 9549, 9550, 9551, 9552, 9553, 9554, 9555, 9556, 9557, 9558, 9559, 9560, 9561, 9562, 9563, 9564, 9565, 9566, 9567, 9568, 9569, 9570, 9571, 9572, 9573, 9574, 9575, 9576, 9577, 9578, 9579, 9580, 9581, 9582, 9583, 9584, 9585, 9586, 9587, 9588, 9589, 9590, 9591, 9592, 9593, 9594, 9595, 9596, 9597, 9598, 9599, 9600, 9601, 9602, 9603, 9604, 9605, 9606, 9607, 9608, 9609, 9610, 9611, 9612, 9613, 9614, 9615, 9616, 9617, 9618, 9619, 9620, 9621, 9622, 9623, 9624, 9625, 9626, 9627, 9628, 9629, 9630, 9631, 9632, 9633, 9634, 9635, 9636, 9637, 9638, 9639, 9640, 9641, 9642, 9643, 9644, 9645, 9646, 9647, 9648, 9649, 9650, 9651, 9652, 9653, 9654, 9655, 9656, 9657, 9658, 9659, 9660, 9661, 9662, 9663, 9664, 9665, 9666, 9667, 9668, 9669, 9670, 9671, 9672, 9673, 9674, 9675, 9676, 9677, 9678, 9679, 9680, 9681, 9682, 9683, 9684, 9685, 9686, 9687, 9688, 9689, 9690, 9691, 9692, 9693, 9694, 9695, 9696, 9697, 9698, 9699, 9700, 9701, 9702, 9703, 9704, 9705, 9706, 9707, 9708, 9709, 9710, 9711, 9712, 9713, 9714, 9715, 9716, 9717, 9718, 9719, 9720, 9721, 9722, 9723, 9724, 9725, 9726, 9727, 9728, 9729, 9730, 9731, 9732, 9733, 9734, 9735, 9736, 9737, 9738, 9739, 9740, 9741, 9742, 9743, 9744, 9745, 9746, 9747, 9748, 9749, 9750, 9751, 9752, 9753, 9754, 9755, 9756, 9757, 9758, 9759, 9760, 9761, 9762, 9763, 9764, 9765, 9766, 9767, 9768, 9769, 9770, 9771, 9772, 9773, 9774, 9775, 9776, 9777, 9778, 9779, 9780, 9781, 9782, 9783, 9784, 9785, 9786, 9787, 9788, 9789, 9790, 9791, 9792, 9793, 9794, 9795, 9796, 9797, 9798, 9799, 9800, 9801, 9802, 9803, 9804, 9805, 9806, 9807, 9808, 9809, 9810, 9811, 9812, 9813, 9814, 9815, 9816, 9817, 9818, 9819, 9820, 9821, 9822, 9823, 9824, 9825, 9826, 9827, 9828, 9829, 9830, 9831, 9832, 9833, 9834, 9835, 9836, 9837, 9838, 9839, 9840, 9841, 9842, 9843, 9844, 9845, 9846, 9847, 9848, 9849, 9850, 9851, 9852, 9853, 9854, 9855, 9856, 9857, 9858, 9859, 9860, 9861}\n"
     ]
    }
   ],
   "source": [
    "# 누락된 book_id 확인\n",
    "missing_books = set(range(article_similarity_total.shape[0])) - set(students_books_df['mapped_book_id'].unique())\n",
    "print(\"누락된 book_id:\", missing_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8fadf57-0cff-47ae-b692-2f75dc31ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_article_matrix.shape: (500, 9862)\n",
      "article_similarity_total.shape: (9862, 9862)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: 모든 책 ID를 0부터 len(all_books)-1로 제한\n",
    "all_books = range(article_similarity_total.shape[0])  # 0부터 9861까지\n",
    "book_id_mapping = {book_id: idx for idx, book_id in enumerate(all_books)}\n",
    "\n",
    "# Step 2: 확장된 매트릭스 초기화\n",
    "expanded_matrix = np.zeros((user_article_matrix.shape[0], len(all_books)))\n",
    "\n",
    "# Step 3: book_id 범위 내에서 매트릭스 데이터 복사\n",
    "for i, book_id in enumerate(students_books_df['book_id'].unique()):\n",
    "    if book_id < len(all_books):  # 범위 확인\n",
    "        expanded_matrix[:, book_id] = user_article_matrix[:, i]\n",
    "\n",
    "# Step 4: user_article_matrix 업데이트\n",
    "user_article_matrix = expanded_matrix\n",
    "\n",
    "# Debugging: 최종 크기 확인\n",
    "print(\"user_article_matrix.shape:\", user_article_matrix.shape)\n",
    "print(\"article_similarity_total.shape:\", article_similarity_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be65cc73-a767-4f09-a558-3c59bed6ea05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 9862)\n",
      "(9862, 9862)\n"
     ]
    }
   ],
   "source": [
    "print(user_article_matrix.shape)  # (500, book_id 개수)\n",
    "print(article_similarity_total.shape)  # (book_id 개수, book_id 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d986339-bf6f-4ae9-a2bd-cf2e352de297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천 점수 계산\n",
    "article_predicted_scores = np.dot(user_article_matrix, article_similarity_total)\n",
    "\n",
    "# 점수 정규화\n",
    "scaler = StandardScaler()\n",
    "article_predicted_scores_normalized = scaler.fit_transform(article_predicted_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ff4de48-10eb-45c8-a95f-9aa952584b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      book_id    저자        발행처 출판년도\n",
      "1265   122126  박 신흥    경 인문 화사     \n",
      "4298   395521  김덕 진   다 하다 미디어     \n",
      "5541  1130379   박영준  랜덤하우스 코리아     \n",
      "7499  4452089             학 지사     \n",
      "271    331967   정길화    해내다 출판사     \n"
     ]
    }
   ],
   "source": [
    "# 상위 5개의 책 추천\n",
    "def recommend_books_for_student(student_id, top_n=5):\n",
    "    # 학생 인덱스 찾기\n",
    "    student_idx = students_books_df['student_id'].unique().tolist().index(student_id)\n",
    "    \n",
    "    # 추천 점수 가져오기\n",
    "    scores = article_predicted_scores_normalized[student_idx]\n",
    "    \n",
    "    # 상위 점수 책 인덱스 추출\n",
    "    recommended_indices = scores.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    # 추천된 책 정보 반환\n",
    "    recommended_books = books_df.iloc[recommended_indices]\n",
    "    return recommended_books[['book_id', '저자', '발행처', '출판년도']]\n",
    "\n",
    "# 예시: 학생 ID가 1인 경우 상위 5개 추천\n",
    "student_id = 1\n",
    "recommended_books = recommend_books_for_student(student_id)\n",
    "print(recommended_books)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4892d0a-f3da-4fd6-9039-9cdf24a37a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      book_id   저자     발행처 출판년도\n",
      "8212  1372728  김현옥      밀레     \n",
      "1947  1803565  김정희    학 지사     \n",
      "2566    44285                  \n",
      "431   1898707  강세황  지식 산업사     \n",
      "1048   156957         책 세상     \n"
     ]
    }
   ],
   "source": [
    "# 개인화된 추천 점수 계산\n",
    "def personalized_recommend_books(student_id, top_n=5):\n",
    "    # 학생이 읽은 책 목록 가져오기\n",
    "    student_books = students_books_df[students_books_df['student_id'] == student_id]['book_id'].tolist()\n",
    "    \n",
    "    # 학생이 읽은 책들의 속성 벡터 평균 계산\n",
    "    read_books_indices = books_df[books_df['book_id'].isin(student_books)].index\n",
    "    if len(read_books_indices) > 0:\n",
    "        # 읽은 책들의 유사도 평균 (TF-IDF, Doc2Vec 기반)\n",
    "        personalized_vector = np.mean(article_similarity_total[read_books_indices], axis=0)\n",
    "    else:\n",
    "        # 읽은 책이 없을 경우 전체 평균 사용\n",
    "        personalized_vector = np.mean(article_similarity_total, axis=0)\n",
    "    \n",
    "    # 개인화 점수 기반 추천 계산\n",
    "    scores = np.dot(personalized_vector, article_similarity_total.T)\n",
    "    \n",
    "    # 상위 점수 책 인덱스 추출\n",
    "    recommended_indices = scores.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    # 추천된 책 정보 반환\n",
    "    recommended_books = books_df.iloc[recommended_indices]\n",
    "    return recommended_books[['book_id', '저자', '발행처', '출판년도']]\n",
    "\n",
    "# 예시: 학생 ID가 1인 경우 개인화된 상위 5개 추천\n",
    "student_id = 1\n",
    "personalized_books = personalized_recommend_books(student_id)\n",
    "print(personalized_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f79416b-455c-4572-abf2-a36312829ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천 함수\n",
    "def recommend_books(title, books_df, cosine_sim):\n",
    "    # 입력 서명의 인덱스\n",
    "    if title not in books_df['서명'].values:\n",
    "        print(\"입력한 책 제목이 데이터에 없습니다.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    idx = books_df[books_df['서명'] == title].index[0]\n",
    "    \n",
    "    # 유사도 점수 정렬\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    sim_scores = sim_scores[1:6]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    return df.iloc[book_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4396320c-6180-49b3-845e-e83204f93701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가를 위한 데이터 분리\n",
    "train_df, test_df = train_test_split(students_books_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a697139-b49c-4f35-b8a6-1ea1b91e6da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.Soyeon\\DSAP\\data\\dsap.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1-Score 계산\n",
    "def evaluate_recommender_for_student():\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for _, row in test_df.iterrows():\n",
    "        student_id = row['student_id']\n",
    "        true_book_id = row['book_id']\n",
    "        \n",
    "        # 학생에게 추천된 책\n",
    "        recommended_books = recommend_books_for_student(student_id, top_n=5)['book_id'].values\n",
    "        \n",
    "        # 평가: 추천된 책에 실제 책이 포함되어 있는지 여부\n",
    "        y_true.append(true_book_id in recommended_books)\n",
    "        y_pred.append(1)  # 추천 시스템이 책을 추천했다고 가정\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# 평가 실행\n",
    "evaluate_recommender_for_student()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19e1480f-3e4b-407f-adf0-a9bfbdf8c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.Soyeon\\DSAP\\data\\dsap.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1-Score 계산\n",
    "def personalized_evaluate_recommender():\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for _, row in test_df.iterrows():\n",
    "        student_id = row['student_id']\n",
    "        true_book_id = row['book_id']\n",
    "        \n",
    "        # 학생에게 추천된 책\n",
    "        recommended_books = personalized_recommend_books(student_id, top_n=5)['book_id'].values\n",
    "        \n",
    "        # 평가: 추천된 책에 실제 책이 포함되어 있는지 여부\n",
    "        y_true.append(true_book_id in recommended_books)\n",
    "        y_pred.append(1)  # 추천 시스템이 책을 추천했다고 가정\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# 평가 실행\n",
    "personalized_evaluate_recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "deebf5bb-0b2f-4e0c-8b95-801925ed0c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.Soyeon\\DSAP\\data\\dsap.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1-Score 계산\n",
    "def recommend_books():\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for _, row in test_df.iterrows():\n",
    "        student_id = row['student_id']\n",
    "        true_book_id = row['book_id']\n",
    "        \n",
    "        # 학생에게 추천된 책\n",
    "        recommended_books = personalized_recommend_books(student_id, top_n=5)['book_id'].values\n",
    "        \n",
    "        # 평가: 추천된 책에 실제 책이 포함되어 있는지 여부\n",
    "        y_true.append(true_book_id in recommended_books)\n",
    "        y_pred.append(1)  # 추천 시스템이 책을 추천했다고 가정\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# 평가 실행\n",
    "personalized_evaluate_recommender()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsap.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
